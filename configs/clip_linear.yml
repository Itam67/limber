{
    # image encoder settings
    encoder_name: 'clip_resnet_large',#'clr_identity',
    # adapter_config: {},
    freeze_img_encoder: true,

    # train settings
    batch_size: 256,
    train_steps: 15000,
    lr: 8.0e-4,
    min_lr: 0.0,
    lr_decay_iters: 300000, #This is used for the warmupdecay lr scheduler
    image_enc_lr: 2.0e-6, #not used? or does this get used for the projection layer
    use_image_embed_layernorm: false,
    image_embed_dropout_prob: 0.1,
    image_size: 384,
    image_seq_len: 144,

    gradient_accumulation_steps: 8,
    zero_stage: 2,
    gradient_clipping: 1.0,

    # dataset / save / load settings
    train_dataset_name: 'conceptual_captions',
    train_dataset_dir: '/fsx/cc3m/training',
    eval_dataset_name: 'coco',
    eval_dataset_dir: '/mnt/carp/datasets/mscoco/training',

    encs_dir: 'vanilla_viz_encodings/clip_resnet_large/',


    save: "/mnt/carp/checkpoints/fcrl_no_adapters",
    load: "/mnt/carp/checkpoints/fcrl_no_adapters",

    eval_every: 100,

}